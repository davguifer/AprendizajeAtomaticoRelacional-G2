{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio de las métricas utilizadas para Naive Bayes\n",
    "\n",
    "En esta hoja se va a estudiar como de necesarias son las métricas calculadas para el entreno del modelo de Naive Bayes.\n",
    "\n",
    "Para realizar el estudio vamos a quitar del dataset los atributos relacionados con agrupamientos, con comunidades, con núcleos, y con centralidad, de esta forma veremos como incide en los resultados cada métrica.\n",
    "\n",
    "Vamos a empezar importando las librerias y funciones que utilizaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "np.random.seed(357823)\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos y creación de los atributos y el objetivo\n",
    "\n",
    "Vamos a empezar por importar el dataset con todos los atributos que calculamos para la realización de este trabajo. Luego, separamos el dataset en atributos por los cuales Naive Bayes se va a entrenar. Finalmente, elegiremos el objetivo, que en este caso es un objetivo categórico binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de los csv\n",
    "\n",
    "# Tabla con todas las métricas\n",
    "nodes = pd.read_csv(\"../tablas/tableWithAllAtributes.csv\")\n",
    "\n",
    "# Tabla con todos los atributos sin los de agrupamiento\n",
    "nodesWithoutClustering = pd.read_csv(\"../tablas/tableWithoutClustering.csv\")\n",
    "\n",
    "# Tabla con todos los atributos sin los de comunidades\n",
    "nodesWithoutCommunity = pd.read_csv(\"../tablas/tableWithoutCommunity.csv\")\n",
    "\n",
    "# Tabla con todos los atributos sin los de nucleos\n",
    "nodesWithoutKernel = pd.read_csv(\"../tablas/tableWithoutKernel.csv\")\n",
    "\n",
    "# Tabla con todos los atributos sin los de centralidad\n",
    "nodesWithoutCentrality = pd.read_csv(\"../tablas/tableWithoutCentrality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de los datos para la tabla con todos los atributos\n",
    "atributos_all_discretos = ['name']\n",
    "atributos_all_continuos = ['degree_centrality','closeness_centrality','betweenness_centrality','clustering_coefficient','Square clustering','triangles','greedy_modularity_communities','Core number','asyn_lpa_communities']\n",
    "atributos_all = nodes.loc[:,['id_node'] + atributos_all_discretos + atributos_all_continuos]\n",
    "\n",
    "# Preparación de los datos para la tabla sin los atributos sin los de agrupamiento\n",
    "atributos_WithoutClustering_discretos = ['name']\n",
    "atributos_WithoutClustering_continuos = ['degree_centrality','closeness_centrality','betweenness_centrality','greedy_modularity_communities','Core number','asyn_lpa_communities']\n",
    "atributos_WithoutClustering = nodesWithoutClustering.loc[:,['id_node'] + atributos_WithoutClustering_discretos + atributos_WithoutClustering_continuos]\n",
    "\n",
    "# Preparación de los datos para la tabla sin los atributos sin los de comunidades\n",
    "atributos_WithoutCommunity_discretos = ['name']\n",
    "atributos_WithoutCommunity_continuos = ['degree_centrality','closeness_centrality','betweenness_centrality','clustering_coefficient','Square clustering','triangles','Core number']\n",
    "atributos_WithoutCommunity = nodesWithoutCommunity.loc[:,['id_node'] + atributos_WithoutCommunity_discretos + atributos_WithoutCommunity_continuos]\n",
    "\n",
    "# Preparación de los datos para la tabla sin los atributos sin los de núcleos\n",
    "atributos_WithoutKernel_discretos = ['name']\n",
    "atributos_WithoutKernel_continuos = ['degree_centrality','closeness_centrality','betweenness_centrality','clustering_coefficient','Square clustering','triangles','greedy_modularity_communities','asyn_lpa_communities']\n",
    "atributos_WithoutKernel = nodesWithoutKernel.loc[:,['id_node'] + atributos_WithoutKernel_discretos + atributos_WithoutKernel_continuos]\n",
    "\n",
    "# Preparación de los datos para la tabla sin los atributos sin los de centralidad\n",
    "atributos_WithoutCentrality_discretos = ['name']\n",
    "atributos_WithoutCentrality_continuos = ['clustering_coefficient','Square clustering','triangles','greedy_modularity_communities','Core number','asyn_lpa_communities']\n",
    "atributos_WithoutCentrality = nodesWithoutCentrality.loc[:,['id_node'] + atributos_WithoutCentrality_discretos + atributos_WithoutCentrality_continuos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: ml_target, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elección del objetivo\n",
    "objetivo = nodes['ml_target']\n",
    "objetivo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de los datos\n",
    "\n",
    "Es necesario codificar cualquier columna categórica que el modelo Naive Bayes no pueda manejar directamente. Utilizaremos la codificación adecuada para convertir las categorías en números, discretizaremos algunos valores para trabajar mejor y normalizaremos estos números si es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación\n",
    "codificador_atributos_discretos = OrdinalEncoder() # Crear una instancia de la clase correspondiente\n",
    "codificador_atributos_discretos.fit(atributos_all[atributos_all_discretos]) # Usar el método fit para ajustar a los datos los parámetros de la codificación\n",
    "codificador_atributos_discretos.fit(atributos_WithoutClustering[atributos_WithoutClustering_discretos]) \n",
    "codificador_atributos_discretos.fit(atributos_WithoutCommunity[atributos_WithoutCommunity_discretos]) \n",
    "codificador_atributos_discretos.fit(atributos_WithoutKernel[atributos_WithoutKernel_discretos]) \n",
    "codificador_atributos_discretos.fit(atributos_WithoutCentrality[atributos_WithoutCentrality_discretos]) \n",
    "\n",
    "\n",
    "# Ahora aplicamos el método transform para codificar los datos\n",
    "atributos_all[atributos_all_discretos] = codificador_atributos_discretos.transform(\n",
    "    atributos_all[atributos_all_discretos]\n",
    ")\n",
    "atributos_WithoutClustering[atributos_WithoutClustering_discretos] = codificador_atributos_discretos.transform(\n",
    "    atributos_WithoutClustering[atributos_WithoutClustering_discretos]\n",
    ")\n",
    "atributos_WithoutCommunity[atributos_WithoutCommunity_discretos] = codificador_atributos_discretos.transform(\n",
    "    atributos_WithoutCommunity[atributos_WithoutCommunity_discretos]\n",
    ")\n",
    "atributos_WithoutKernel[atributos_WithoutKernel_discretos] = codificador_atributos_discretos.transform(\n",
    "    atributos_WithoutKernel[atributos_WithoutKernel_discretos]\n",
    ")\n",
    "atributos_WithoutCentrality[atributos_WithoutCentrality_discretos] = codificador_atributos_discretos.transform(\n",
    "    atributos_WithoutCentrality[atributos_WithoutCentrality_discretos]\n",
    ")\n",
    "\n",
    "\n",
    "# Normalizamos el name\n",
    "normalizador = MinMaxScaler(\n",
    "    # Cada atributo se normaliza al intervalo [0, 1]\n",
    "    feature_range=(0, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Aplicamos la normalización solo a la columna 'name'\n",
    "atributos_all['name'] = normalizador.fit_transform(atributos_all[['name']])\n",
    "atributos_WithoutClustering['name'] = normalizador.fit_transform(atributos_WithoutClustering[['name']])\n",
    "atributos_WithoutCommunity['name'] = normalizador.fit_transform(atributos_WithoutCommunity[['name']])\n",
    "atributos_WithoutKernel['name'] = normalizador.fit_transform(atributos_WithoutKernel[['name']])\n",
    "atributos_WithoutCentrality['name'] = normalizador.fit_transform(atributos_WithoutCentrality[['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizamos:\n",
    "# Discretizamos usando uniform ya que si usamos la estrategia de quantile se eliminan datos por ser los intervalos demasiado pequeños\n",
    "discretizador = KBinsDiscretizer(\n",
    "    n_bins=700,  # Hemos 700 intervalos ya que es como mejor rendimiento saca para los valores que hemos probado\n",
    "    encode='ordinal',  # Los intervalos se codifican numéricamente\n",
    "    strategy='uniform'  # Intervalos de igual tamaño\n",
    "    )\n",
    "\n",
    "# Como nos interesa conservar los atributos continuos originales, realizamos\n",
    "# la discretización sobre una copia del DataFrame de atributos\n",
    "atributos_all_discretizados = atributos_all.copy()\n",
    "atributos_WithoutClustering_discretizados = atributos_WithoutClustering.copy()\n",
    "atributos_WithoutCommunity_discretizados = atributos_WithoutCommunity.copy()\n",
    "atributos_WithoutKernel_discretizados = atributos_WithoutKernel.copy()\n",
    "atributos_WithoutCentrality_discretizados = atributos_WithoutCentrality.copy()\n",
    "\n",
    "\n",
    "atributos_all_discretizados[atributos_all_continuos] = discretizador.fit_transform(\n",
    "    atributos_all_discretizados[atributos_all_continuos]\n",
    ")\n",
    "atributos_WithoutClustering_discretizados[atributos_WithoutClustering_continuos] = discretizador.fit_transform(\n",
    "    atributos_WithoutClustering_discretizados[atributos_WithoutClustering_continuos]\n",
    ")\n",
    "atributos_WithoutCommunity_discretizados[atributos_WithoutCommunity_continuos] = discretizador.fit_transform(\n",
    "    atributos_WithoutCommunity_discretizados[atributos_WithoutCommunity_continuos]\n",
    ")\n",
    "atributos_WithoutKernel_discretizados[atributos_WithoutKernel_continuos] = discretizador.fit_transform(\n",
    "    atributos_WithoutKernel_discretizados[atributos_WithoutKernel_continuos]\n",
    ")\n",
    "atributos_WithoutCentrality_discretizados[atributos_WithoutCentrality_continuos] = discretizador.fit_transform(\n",
    "    atributos_WithoutCentrality_discretizados[atributos_WithoutCentrality_continuos]\n",
    ")\n",
    "\n",
    "# El id_node no lo discretizamos, al igual que el name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Validación por retención\n",
    "\n",
    "Ahora vamos a comprobar si los resultados de los hiperparámetros elegidos son acertados. Dividiremos el dataset en datos de entrenamiento y datos de prueba. En este caso, usaremos un 80% de los datos para entrenar y un 20% para probar. Entrenaremos el clasificador Naive Bayes con diferentes configuraciones de hiperparámetros y evaluaremos su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con todas las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con alpha = 1 que es el mejor valor\n",
    "tubería_NB1 = Pipeline([('preprocesador', discretizador),\n",
    "                       ('naive_Bayes', CategoricalNB(alpha=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.036937  , 0.04374313, 0.04089642, 0.0404067 , 0.03677773,\n",
       "        0.03590965, 0.03890109, 0.03790307, 0.03538179, 0.03758812]),\n",
       " 'score_time': array([0.00598621, 0.00897765, 0.00897646, 0.00698328, 0.00667167,\n",
       "        0.00598454, 0.00698256, 0.00700283, 0.00598598, 0.01895261]),\n",
       " 'test_score': array([0.94552929, 0.67659138, 0.68172485, 0.65195072, 0.68069815,\n",
       "        0.66016427, 0.70020534, 0.66427105, 0.65297741, 0.94661191])}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación cruzada para Alpha óptimo (Alpha = 1)\n",
    "resultados_validación_cruzadaConAlphaOptimo_all = cross_validate(tubería_NB1,\n",
    "                                               atributos_all_discretizados,\n",
    "                                               objetivo,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzadaConAlphaOptimo_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7260724362721616"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzadaConAlphaOptimo_all['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin las métricas de agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0309217 , 0.03590989, 0.02992368, 0.02992654, 0.02892971,\n",
       "        0.02813029, 0.02740312, 0.02714729, 0.02596116, 0.02593851]),\n",
       " 'score_time': array([0.00797963, 0.00598431, 0.00658417, 0.00598192, 0.00505805,\n",
       "        0.00495815, 0.00601506, 0.00501132, 0.00598764, 0.00598478]),\n",
       " 'test_score': array([0.96505653, 0.66940452, 0.66632444, 0.63552361, 0.6724846 ,\n",
       "        0.65400411, 0.68788501, 0.66427105, 0.65400411, 0.97227926])}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación cruzada para Alpha óptimo (Alpha = 1)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutClustering = cross_validate(tubería_NB1,\n",
    "                                               atributos_WithoutClustering_discretizados,\n",
    "                                               objetivo,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241237224359557"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzadaConAlphaOptimo_WithoutClustering['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin las métricas de comunidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03369498, 0.03490996, 0.03445506, 0.03360343, 0.03092122,\n",
       "        0.03045654, 0.02865815, 0.03033304, 0.03496623, 0.03113961]),\n",
       " 'score_time': array([0.00698256, 0.00698233, 0.00635672, 0.00698185, 0.00552011,\n",
       "        0.0053072 , 0.006675  , 0.00646377, 0.00601387, 0.00656581]),\n",
       " 'test_score': array([0.94450154, 0.59240246, 0.58213552, 0.58829569, 0.5862423 ,\n",
       "        0.57494867, 0.63655031, 0.58829569, 0.57802875, 0.94353183])}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación cruzada para Alpha óptimo (Alpha = 1)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutCommunity = cross_validate(tubería_NB1,\n",
    "                                               atributos_WithoutCommunity_discretizados,\n",
    "                                               objetivo,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutCommunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6614932753122817"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzadaConAlphaOptimo_WithoutCommunity['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin las métricas de núcleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03378606, 0.02902746, 0.02803874, 0.03055549, 0.02995563,\n",
       "        0.03088093, 0.0297184 , 0.02967143, 0.03043199, 0.03016949]),\n",
       " 'score_time': array([0.006387  , 0.00498724, 0.0059855 , 0.00564575, 0.00498772,\n",
       "        0.004987  , 0.0059855 , 0.00562525, 0.00598621, 0.00498796]),\n",
       " 'test_score': array([0.95786228, 0.67043121, 0.66529774, 0.64373717, 0.67864476,\n",
       "        0.66427105, 0.69712526, 0.6550308 , 0.65195072, 0.96201232])}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación cruzada para Alpha óptimo (Alpha = 1)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutKernel = cross_validate(tubería_NB1,\n",
    "                                               atributos_WithoutKernel_discretizados,\n",
    "                                               objetivo,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7246363308297334"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzadaConAlphaOptimo_WithoutKernel['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin las métricas de centralidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03745127, 0.02844119, 0.025038  , 0.02487874, 0.02547359,\n",
       "        0.02523804, 0.02636719, 0.02698612, 0.02599764, 0.02844644]),\n",
       " 'score_time': array([0.00698543, 0.0069766 , 0.00598526, 0.00498724, 0.005018  ,\n",
       "        0.00601387, 0.0050106 , 0.00501585, 0.00610232, 0.00598526]),\n",
       " 'test_score': array([0.97636177, 0.68172485, 0.67145791, 0.66427105, 0.68172485,\n",
       "        0.67351129, 0.70123203, 0.66324435, 0.64784394, 0.97741273])}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación cruzada para Alpha óptimo (Alpha = 1)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutCentrality = cross_validate(tubería_NB1,\n",
    "                                               atributos_WithoutCentrality_discretizados,\n",
    "                                               objetivo,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzadaConAlphaOptimo_WithoutCentrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7338784765675286"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzadaConAlphaOptimo_WithoutCentrality['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones del estudio\n",
    "\n",
    "Como podemos ver el siguente recuadro, para nuestro problema las métricas de comunidad son muy importante, ya que bajan la confianza en un 6,45%, las métricas de centralidad no son necesarias ya que sin ella el modelo de Naive Bayes consigue una mejor confianza, en el caso de no tener la de centralidad sube en un 0,79%. Por último sin las métricas de agrupamiento y de núcleo la confianza es prácticamente la misma (aunque empeora un poco), esto quiere decir que aunque no las tengamos se puede llegar a tener una buena confianza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confianza del dataser con todas las métricas: 0.7260724362721616\n",
      "Confianza del dataser sin las métricas de agrupamiento: 0.7241237224359557\n",
      "Confianza del dataser sin las métricas de comunidad: 0.6614932753122817\n",
      "Confianza del dataser sin las métricas de núcleo: 0.7246363308297334\n",
      "Confianza del dataser sin las métricas de centralidad: 0.7338784765675286\n"
     ]
    }
   ],
   "source": [
    "print(\"Confianza del dataser con todas las métricas:\",resultados_validación_cruzadaConAlphaOptimo_all['test_score'].mean())\n",
    "print(\"Confianza del dataser sin las métricas de agrupamiento:\",resultados_validación_cruzadaConAlphaOptimo_WithoutClustering['test_score'].mean())\n",
    "print(\"Confianza del dataser sin las métricas de comunidad:\",resultados_validación_cruzadaConAlphaOptimo_WithoutCommunity['test_score'].mean())\n",
    "print(\"Confianza del dataser sin las métricas de núcleo:\",resultados_validación_cruzadaConAlphaOptimo_WithoutKernel['test_score'].mean())\n",
    "print(\"Confianza del dataser sin las métricas de centralidad:\",resultados_validación_cruzadaConAlphaOptimo_WithoutCentrality['test_score'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
